# Grid-Based Path Finding Competition Starter Kit

## Grid Track

Website [https://gppc.search-conference.org/grid](https://gppc.search-conference.org/grid)

## Submission Instruction

Read the [Submission_Instruction.md](https://github.com/gppc-dev/startkit-anyangle/blob/master/Submission_Instruction.md)

## Problem Definition

Read the [Problem_Definition.md](https://github.com/gppc-dev/startkit-classic/blob/master/Problem_Definition.md)

# TLDR

* Participants push commits to their repositories and the server will pull, compile, run and evaluate the current head of the main branch.

  * participants can add new repo via our web interface
  * participants must specify their dependency in `apt.txt` (we provide a sample in `startkit`)
  * server will build a docker image to compile, run and evaluate submissions

# Start Kit

This startkit uses shared library (`lib/libGPPCentry.so` on Linux competition machine)
for their code implementation.
The runtime app `./run` can be generated by the local user; however, it will be replaced by a server
built version on evaluation.

The following files, how to use them and if they are required by the server are detailed below:

| File name             | Description                                                     | Required   |
| --------------------- | --------------------------------------------------------------- | ---------- |
| `gppc/*`              | Compiles a local `run` for user testing                         | no         |
| `Entry.h`             | Header to shared library entry.  Only needed to build.          | no         |
| `version.txt`         | Startkit version                                                | no         |
| `Entry.cpp`           | C++ default implementation paired to `Entry.h`                  | no         |
| `Entry.c  `           | C default implementation paired to `Entry.h`                    | no         |
| `compile.sh`          | Compile to produce `lib/libGPPCentry.so`, optional `./run`      | yes        |
| `apt.txt`             | Define dependency, will be used by server to build docker image | yes        |

The `./compile.sh`, or server `./run` may generate the following files:

| File name     | Description                                                                  | Optional |
| ------------- | ---------------------------------------------------------------------------- | -------- |
| `run`         | compiled executable, server uses own compiled version                        | no       |
| `run.stdout`  | stdout is redirected to here. Computed paths goes to stdout for validation.  | no       |
| `run.stderr`  | stderr redirected to here                                                    | no       |
| `run.info`    | stores some run time information                                             | no       |
| `result.csv`  | stores query information, including time cost, path length, etc.             | no       |
| `index_data/` | if your algorithm has pre-computation, all produced data must be here        | yes      |

The source language used for implementation is for the user.  So long as a compiler is present (add to `apt.txt`)
and `./compile.sh` produces a working `lib/libGPPCentry.so` that pairs with the provided `Entry.h`, it should be
compatible with the competition server.

NOTE: the server `run` generated is separate to the code startkit, there are no guarantees that the `./run`
generated by the server will behave the same as the one generated from `./gppc`.
It is guaranteed that the server `run` will be compatible with a user generated `lib/libGPPCentry.so` provided it
follows `Entry.h` specifications, see header for details on function call usage and observe pointer lifetimes.

## Your Implementation
* Implement `gppc_preprocess_init_map`, `gppc_search_init`, `gppc_map_change`, `gppc_get_path`, `gppc_free_data` and `gppc_get_name` for shared library.  Modify `Entry.cpp` for C++ and `Entry.c` for C.
* Specify your dependency packages in `apt.txt`. The packages must be available for installation through `apt-get` on Ubuntu 22.
* Modify `compile.sh` and make sure your code can be compiled by executing this script.  It must work under Linux Ubuntu 22 with the packages in `apt.txt` to produce a working shared library `lib/libGPPCentry.so`.

Default compiling is handled by CMake, using the C++ version.  If using C binding implementation `Entry.c`,
switch the included source code in `./CMakeLists.txt` for these files with the command `add_library(GPPCentry`
(switch comment on lines 16/17).  Only one should be included to prevent duplicate definitions.
The `compile.sh` script installs these files to the source directory, this is required to set the `rpath`
for linkage with the local `./run`, but is not required for the server if only building `lib/libGPPCentry.so`
with no library dependencies.

If not on Linux, the `./run` produced by the default `compile.sh` may not find link to `lib/libGPPCentry.so`,
use the `run` located in the CMake build directly instead (e.g. `auto_build/gppc/run`).

If using a different shared library compiling system (no CMake),
or want to link your library against another library then check out the Advanced Compiling subsection
for advice.

## Run the Program
* `./run -pre <map> none` Run in preprocessing mode. The program should preprocess the given map and store the preprocessing data under `index_data/`.
* `./run -check <map> <scen>` Run in validation mode. The output will be validated. Each entry of the `run.stdout` will be marked as `valid` or `invalid-i`, where `i` indicate which segment of the path is invalid.
* `./run -run <map> <scen>` Run in benchmark mode. The benchmark results are written to `result.csv`.

## Customise Program Runtime

Environmental variables are defined to enable features not strictly required for development.
They are listed below:

* `GPPC_REDIRECT_OUTPUT`: redirects `stdout`/`stderr` to files, as detailed in I/O Setup section.
* `GPPC_MEMORY_TRACK`: prints memory usage into `run.info` file, available on Linux only.
  
## Advanced Compiling

This subsection detailed linking advice, only applicable if having your shared library
link against another in most cases and assumes you are working on Linux.

If for reasons you want to switch out CMake for generating `lib/libGPPCentry.so`,
it can be as simple as modifying the `./compile.sh` to generate the library file `lib/libGPPCentry.so`.

It is recommended to test your implementation locally on `./run`, to do so comment out
the `add_library` and `install` for target `GPPCentry` from `./CMakeLists.txt` (lines 14-20), and run the default
`./comile.sh` lines 5-8, or just CMake build and install to current directory, will allow for a local
`./run` against any `lib/libGPPCentry.so` provided.

Shared libraries require information to on library paths in order to be linked.  The server side handles this link
for `run`, while the shared libraries contains its own linkage (through `ld` linker), unless your code links
against another library this is not a concern on the user end.

If you do require another linkage, it may be necessary to set the `rpath` of the shared library to `${ORIGIN}`.
In CMake, this can be done either by either changing line 7 of `./CMakeLists.txt`
to `set(CMAKE_INSTALL_RPATH \${ORIGIN}/lib:\${ORIGIN})` (`\${ORIGIN}/lib` is required for `./run`),
or adding it with `set_property(GPPCentry PROPERTIES INSTALL_RPATH "\${ORIGIN}:${INSTALL_RPATH}")`,
both methods require a CMake install to set on the library .so file.

You can check an executable linkage with command `ldd`, or get more details in liked libraries and
rpath with `readelf -d` (rpath will be under `RUNPATH`).

If compiling with static libraries into the shared libraries, Linux may require `-fPIC` flab be used with
those static libraries as well.  CMake has configured to do this by default, due to the setting:
`set(CMAKE_POSITION_INDEPENDENT_CODE TRUE)`. 

# Details on the server side

For those who **want to build local testing workflow**, this section might be helpful.

## I/O Setup

* All `stdout` from program are redirected to a file `run.stdout`. Your codes should not print any debug info to `stdout`

* All `stderr` are redirected to a file `run.stderr`

* The results of benchmark (i.e. `./run -run <map> <scen>`) are written to `result.csv`

* All these files are in docker, and will backup to server so that we can hide/reveal information to participants.


## Execution Setup

* The server run all scripts under certain constraints, e.g. time limit, memory limit.

* A execution will be killed by server when it exceeds limits, and participants will get `Time Limit Exceed` / `Memory Limit Exceed` verdict.

* If an execution crashed, participants will get `Run Time Error` verdict with few or none hints.

* Participants can submit their solution and execute in `dev` mode for testing purpose, in `dev` mode:
  * we only test a small set of simple map
  * we will reveal all `stdout` and `stderr` to participants
  * this mode is to eliminate compile errors and illegal output format.
  * although participants can do this locally, we encourage everyone to submit on `dev` mode at least once.


## Evaluation Workflow

### Overview
1. Build docker image based on the apt.txt in submission repo.
2. Start the container in background.
3. Run pre-processing for debug maps.
4. Run validation for debug scenarios.
5. Run pre-processing for benchmark maps.
6. Run validation for benchmark scenarios.
7. Run benchmark for benchmark scenarios.
8. Submit final result.


# Test Your Implementation in a Docker Environment

* Install latest docker release on your machine, [https://docs.docker.com/engine/install/](https://docs.docker.com/engine/install/).

* Setting up environment using `RunInDocker.sh`:
  * In the root of your code base, run command `./RunInDocker.sh`. This script will automatically generate a Dockerfile to build the docker image.
  * It will copy your codes to the Docker Environment, install dependencies listed in `apt.txt` using apt-get, and compile your code using `compile.sh`.
  * You are inside the docker container when the script finishes.
  * You can run the compiled program in side docker container now.
  * The docker image name `<image name>` is `gppc_image` and the container name `<container name>` is `gppc_test`.
  * Exit the container with command: `exit`.
* Or you also can set up environment manually:
  * Prepare your Dockerfile, which uses `ubuntu:jammy` as the base image.
  * The docker image working directory should be set to the directory where executables are. The docker image should copy user implementation into the image.
  * `docker build -t <image name> <dockerfile>`: build docker image based on a default/user-defined Dockerfile.
  * Building executable:
    * The Dockerfile include a RUN command that running a user provided compile script `./compile.sh` to build executable.
  * `docker run -it --name <container name> <image name>`: start the container interactively.

* Start an existing container:
  * In background: `docker container start <container name>`
  * Interactively: `docker container start -i <container name>`

* The docker container is started in background, you can run commands from the outside of the docker container (treat docker container as executable).
 
  * Use prefix: `docker container exec <container name>` for all following commands
 
  * Running preprocessing:
    * `<prefix> ./run -pre ${map_path} none`: run user provided preprocessing codes.

  * Running executable with the validator
    * `<prefix> ./run -check ${map_path} ${scenario_path} `
    * With `-check` flag, the output will be validated by a validator. Each entry of the output will be marked as `valid` or `invalid-i`, where `i` indicate which segment of the path is invalid.

  * Running executable for benchmarking: `<prefix> ./run -run ${map_path} ${scenario_path}`
    * we will track time/memory usage and publish results
 
  * All outputs are stored inside the container. You could copy files from docker container. For example: `docker cp gppc_test:/GPPC2021/codes/run.stdout ./run.stdout`, which copies `run.stdout` to your current working directory.
